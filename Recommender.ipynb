{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a6e635c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "import unicodedata\n",
    "import re\n",
    "from cleanco import basename\n",
    "import csv\n",
    "import yfinance as yf\n",
    "import wikipedia\n",
    "import nltk\n",
    "import string\n",
    "from nltk.util import ngrams\n",
    "from fuzzywuzzy import fuzz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "154f7e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class model: \n",
    "    def __init__(self, test_filename=None):\n",
    "        self.data = self.load_data()\n",
    "        if test_filename:\n",
    "            self.test = self.test_cases(test_filename)\n",
    "            \n",
    "    def load_raw(self):\n",
    "        ###this method was used to grab original raw data provided; not used in the main method \n",
    "        response = requests.get(\"https://www.sec.gov/files/company_tickers.json\")\n",
    "\n",
    "        data_object = json.loads(response.text)\n",
    "        \n",
    "        df = pd.DataFrame.from_dict(data_object, orient='index')\n",
    "        \n",
    "        return df\n",
    "        \n",
    "    def query_yahoo_data(self,filename): \n",
    "        ###This script is to add summary into to the data file -> resulting data is saved under data/company_data.csv\n",
    "        if self.data_processed: \n",
    "            with open(filename, 'w', newline='', encoding=\"utf-8\") as csvfile:\n",
    "                fieldnames = [\"ticker\", \"title\", \"summary\"]\n",
    "                writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "                writer.writeheader()\n",
    "\n",
    "                for index, row in self.data.iterrows():\n",
    "\n",
    "                    try: \n",
    "                        stock_info = {\n",
    "                            \"ticker\": row.ticker,\n",
    "                            \"title\": row.title, \n",
    "                            \"summary\": yf.Ticker(row.ticker).info[\"regularMarketDescription\"]                \n",
    "                        }\n",
    "                        print('number of rows added [%d]\\r'%int(index), end=\"\")\n",
    "\n",
    "                        writer.writerow(stock_info)\n",
    "\n",
    "                    except Exception as e: \n",
    "                        print(e)\n",
    "        return \n",
    "      \n",
    "    def extract_nouns(self, text):\n",
    "        ###This method is to extract all proper nouns or words with the first letter being capital\n",
    "        \n",
    "        # Tokenize the text\n",
    "        tokens = nltk.word_tokenize(text)\n",
    "\n",
    "        # Extract the nouns using a regular expression\n",
    "        pattern = r'\\b[A-Z0-9][^\\s]*\\b'\n",
    "        nouns = re.findall(pattern, text)\n",
    "        \n",
    "        #join back to a string \n",
    "        return \" \".join(nouns)\n",
    "    \n",
    "    def remove_duplicates(self,text):\n",
    "        ###this method is not being used; for testing purpose to see if reducing duplicates in summary text is more effective\n",
    "        \n",
    "        # Split the string into a list of words\n",
    "        words = text.split()\n",
    "\n",
    "        # Remove duplicates from the list\n",
    "        words = list(set(words))\n",
    "\n",
    "        # Join the list back into a single string\n",
    "        return \" \".join(words)\n",
    "    \n",
    "    def remove_punctuation(self, input_string):\n",
    "        ###this method is used to remove all special characters \n",
    "        \n",
    "        # Make a translator object to remove punctuation\n",
    "        translator = str.maketrans('', '', string.punctuation)\n",
    "\n",
    "        # Use this object to remove the punctuation from the input string\n",
    "        no_punct = input_string.translate(translator)\n",
    "        return no_punct\n",
    "    \n",
    "    def calculate_occurence(self, input_val, summary_text):\n",
    "        ###this is main algorithm for processing summary text. \n",
    "        ###I generate all ngram substring of summary text based on length of input_value to evaluate under fuzz.token_set_ratio method\n",
    "        ###I specify full_process to be False as it needs to capture proper nouns and cannot be lowercased \n",
    "        \n",
    "        sum_val = 0\n",
    "        if summary_text:\n",
    "            for s1 in ngrams(summary_text.split(), len(input_val.split())):\n",
    "                for gram in s1:\n",
    "                    ratio = fuzz.token_set_ratio(gram.lower(), input_val, full_process=False)\n",
    "                    if ratio >= 85: \n",
    "                        sum_val += ratio\n",
    "        return sum_val \n",
    "        \n",
    "    def load_data(self):\n",
    "        ###this method will automatically trigger when the class is initilized to load the starting data \n",
    "        ###It will clean the data in a dataframe format then return \n",
    "        total_df = pd.read_csv(\"data/company_data.csv\",encoding='latin-1')\n",
    "        total_df = total_df.dropna()\n",
    "        total_df = total_df.drop_duplicates(subset=\"ticker\")\n",
    "        total_df = total_df.drop_duplicates(subset=\"title\")\n",
    "\n",
    "        total_df[\"summary\"] = total_df[\"summary\"].apply(lambda text: self.extract_nouns(text))\n",
    "\n",
    "        # total_df[\"summary\"] = total_df[\"summary\"].apply(lambda text: self.remove_duplicates(text))\n",
    "        total_df[\"summary\"] = total_df[\"summary\"].apply(lambda text: self.remove_punctuation(text))\n",
    "\n",
    "        total_df[\"title\"] = total_df[\"title\"].str.lower()\n",
    "        total_df[\"title\"] = total_df[\"title\"].str.strip()\n",
    "        total_df[\"title\"] = total_df[\"title\"].apply(lambda company: re.sub(r\"\\(.*\\)\", \"\", company))\n",
    "        total_df[\"title\"] = total_df[\"title\"].apply(lambda text: self.remove_punctuation(text))\n",
    "        total_df[\"title\"] = total_df[\"title\"].apply(lambda company: re.sub(r\"\\b(com|class|a|b|ordinary|depositary|shares|share|common|stock|cap|ix|manufacturing|incorporated|platforms|enterprises|manufacturing|company|companies|inc|corp|co|de|ltd|nv|plc|ag|us|se|asa|llc|holdings|holding|mobil|pharmaceuticals|limited|gmbh|sa|lp)\\b\", \"\", company))\n",
    "        total_df[\"title\"] = total_df[\"title\"].str.strip()\n",
    "        return total_df\n",
    "        \n",
    "    def predict(self, input_data, predict_type=None):\n",
    "        ###this is the main method for predicting given an input string \n",
    "        ###if predict type is None it will return a ticker:string \n",
    "        ###if predict type is \"test\" it will return a dataframe with the first 5 rows\n",
    "        \n",
    "        \n",
    "        #given input is first cleaned\n",
    "        input_data = re.sub(r\"\\(.*\\)\", \"\", input_data)\n",
    "        input_data = input_data.lower().strip()\n",
    "        input_data = re.sub(r\"\\(.*\\)\", \"\", input_data)\n",
    "        \n",
    "        input_data = self.remove_punctuation(input_data)\n",
    "        input_data = re.sub(r\"\\b(com|cap|ix|incorporated|class|a|b|common|stock|shares|share|ordinary|depositary|manufacturing|platforms|enterprises|corporation|company|companies|inc|corp|co|de|ltd|nv|plc|ag|us|se|asa|llc|holdings|holding|mobil|pharmaceuticals|limited|gmbh|sa|lp)\\b\", \"\", input_data)\n",
    "        input_data = input_data.strip()\n",
    "        \n",
    "        #given input is compared against ticker \n",
    "        self.data[\"ratio_ticker\"] = self.data[\"ticker\"].apply(lambda text: \n",
    "                                                                  fuzz.ratio(input_data.lower(), text.lower()) \n",
    "                                                             )\n",
    "        self.data[\"ratio_ticker\"] = self.data[\"ratio_ticker\"].apply(lambda ratio: 0 if ratio<=80 else ratio)\n",
    "\n",
    "        #given input is compared against title \n",
    "        self.data[\"ratio_title\"] = self.data[\"title\"].apply(lambda text: \n",
    "                                                                fuzz.ratio(input_data.lower(), text) \n",
    "                                                           )\n",
    "        self.data[\"ratio_title\"] = self.data[\"ratio_title\"].apply(lambda ratio: 0 if ratio<=80 else ratio)\n",
    "\n",
    "        #given input is compared against summary \n",
    "        self.data[\"ratio_summary\"] = self.data[\"summary\"].apply(lambda text: self.calculate_occurence(input_data.lower(), text))\n",
    "        self.data[\"ratio_total\"] = self.data[\"ratio_ticker\"] + self.data[\"ratio_title\"] + self.data[\"ratio_summary\"]\n",
    "        \n",
    "        if predict_type == \"test\":\n",
    "            return self.data.sort_values(by=[\"ratio_title\", \"ratio_ticker\", \"ratio_summary\"],ascending=[False, False, False]).head()\n",
    "        \n",
    "        return self.data.sort_values(by=[\"ratio_title\", \"ratio_ticker\", \"ratio_summary\"],ascending=[False, False, False]).iloc[0][\"ticker\"]\n",
    "\n",
    "    \n",
    "    def test_cases(self, filename):\n",
    "        ###for testing purposes\n",
    "        \n",
    "        #or use sp500_data.csv for sp500 data\n",
    "        test = pd.read_csv(\"data/nasdaq_screener.csv\")\n",
    "        test = pd.merge(self.data, test, left_on=\"ticker\", right_on=\"Symbol\", how=\"inner\")\n",
    "        test = test[[\"Name\", \"Symbol\"]]\n",
    "        test[\"result\"] = None\n",
    "        test[\"ratio_title\"] = None\n",
    "        test[\"ratio_ticker\"] = None\n",
    "        test[\"ratio_summary\"] = None\n",
    "        test[\"ratio_total\"] = None\n",
    "        \n",
    "        #samples 100 rows without replacement \n",
    "        test = test.sample(n=100, replace=False)\n",
    "        num_rows = 0 \n",
    "        \n",
    "        #iterates through each input and generate a prediction \n",
    "        for index, row in test.iterrows():\n",
    "            try:\n",
    "                input_data = row[\"Name\"]\n",
    "                result = self.predict(input_data, predict_type = \"test\") \n",
    "                result_ticker = result[\"ticker\"]\n",
    "                ratio_title = result[\"ratio_title\"]\n",
    "                ratio_ticker = result[\"ratio_ticker\"]\n",
    "                ratio_summary = result[\"ratio_summary\"]\n",
    "                total_ratio = result[\"ratio_total\"]\n",
    "                \n",
    "                \n",
    "                test.at[index, \"result\"] = result_ticker\n",
    "                test.at[index, \"ratio_title\"] = ratio_title\n",
    "                test.at[index, \"ratio_ticker\"] = ratio_ticker\n",
    "                test.at[index, \"ratio_summary\"] = ratio_summary\n",
    "                test.at[index, \"ratio_total\"] = total_ratio\n",
    "                \n",
    "                \n",
    "                print('number of rows tested [%d]\\r'%int(num_rows), end=\"\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "            \n",
    "            num_rows+=1\n",
    "            \n",
    "        test.to_csv(filename)\n",
    "        \n",
    "        return \n",
    "    \n",
    "    def output_dictionary(self,dictionary): \n",
    " \n",
    "        # name of csv file\n",
    "        filename = \"output.csv\"\n",
    "\n",
    "        # writing to csv file\n",
    "        with open(filename, 'w') as csvfile:\n",
    "            # creating a csv dict writer object\n",
    "            writer = csv.DictWriter(csvfile,  fieldnames = [\"accuracy\", \n",
    "                                                            \"tital_hit_overall\", \n",
    "                                                            \"title_hit_accurate\",\n",
    "                                                            \"title_ratio\",\n",
    "                                                            \"ticker_hit_overall\",\n",
    "                                                            \"ticker_hit_accurate\",\n",
    "                                                            \"ticker_ratio\",\n",
    "                                                            \"summary_hit_overall\", \n",
    "                                                            \"summary_hit_accurate\", \n",
    "                                                            \"summary_ratio\", \n",
    "                                                            \"average_overall_score\", \n",
    "                                                            \"average_accurate_score\"\n",
    "                                                           ])\n",
    "\n",
    "            # writing headers (field names)\n",
    "            writer.writeheader()\n",
    "\n",
    "            # writing data rows\n",
    "            writer.writerow(dictionary)\n",
    "    \n",
    "    def analyze_test(self, filename):\n",
    "        ###this method is to analyze the csv output from test cases method \n",
    "        \n",
    "        test = pd.read_csv(filename)\n",
    "        test[\"result_bool\"] = test[\"Symbol\"]==test[\"result\"]\n",
    "            \n",
    "        true_df = test[test[\"result_bool\"]==True]\n",
    "        \n",
    "        accuracy = (len(test[test[\"result_bool\"] == True])/len(test))*100\n",
    "        \n",
    "        title_hit_overall = (len(test[test[\"ratio_title\"]!=0])/len(test)) *100\n",
    "        title_hit_accurate = (len(true_df[true_df[\"ratio_title\"]!=0])/len(test))*100\n",
    "        if title_hit_overall:\n",
    "            title_accurate_overall = title_hit_accurate/title_hit_overall\n",
    "        else: \n",
    "            title_accurate_overall = 0 \n",
    "        \n",
    "        ticker_hit_overall = (len(test[(test[\"ratio_title\"]==0)&(test[\"ratio_ticker\"]!=0)])/len(test))*100\n",
    "        ticker_hit_accurate = (len(true_df[(true_df[\"ratio_title\"]==0)&(true_df[\"ratio_ticker\"]!=0)])/len(test))*100  \n",
    "        if ticker_hit_overall:\n",
    "            ticker_accurate_overall = ticker_hit_accurate/ticker_hit_overall\n",
    "        else: \n",
    "            ticker_accurate_overall = 0 \n",
    "        \n",
    "        summary_hit_overall = (len(test[(test[\"ratio_title\"]==0)&(test[\"ratio_ticker\"]==0)&(test[\"ratio_summary\"]!=0)])/len(test))*100 \n",
    "        summary_hit_accurate = (len(true_df[(true_df[\"ratio_title\"]==0)&(true_df[\"ratio_ticker\"]==0)&(true_df[\"ratio_summary\"]!=0)])/len(test))*100\n",
    "        if summary_hit_overall:\n",
    "            summary_accurate_overall = summary_hit_accurate/summary_hit_overall\n",
    "        else: \n",
    "            summary_accurate_overall = 0 \n",
    "        \n",
    "  \n",
    "        average_overall_score = sum(test[\"ratio_total\"])/len(test)\n",
    "        average_accurate_score = sum(true_df[\"ratio_total\"])/len(true_df)   \n",
    "        \n",
    "        result = {\n",
    "            \"accuracy\": accuracy, \n",
    "            \"tital_hit_overall\": title_hit_overall, \n",
    "            \"title_hit_accurate\": title_hit_accurate, \n",
    "            \"title_ratio\":title_accurate_overall, \n",
    "            \"ticker_hit_overall\": ticker_hit_overall, \n",
    "            \"ticker_hit_accurate\": ticker_hit_accurate, \n",
    "            \"ticker_ratio\": ticker_accurate_overall, \n",
    "            \"summary_hit_overall\":summary_hit_overall, \n",
    "            \"summary_hit_accurate\": summary_hit_accurate, \n",
    "            \"summary_ratio\": summary_accurate_overall, \n",
    "            \"average_overall_score\": average_overall_score, \n",
    "            \"average_accurate_score\": average_accurate_score\n",
    "        }\n",
    "        \n",
    "        self.output_dictionary(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca8c4fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "mymodel = model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3afc4712",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticker</th>\n",
       "      <th>title</th>\n",
       "      <th>summary</th>\n",
       "      <th>ratio_ticker</th>\n",
       "      <th>ratio_title</th>\n",
       "      <th>ratio_summary</th>\n",
       "      <th>ratio_total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>AMZN</td>\n",
       "      <td>amazon</td>\n",
       "      <td>Amazoncom Inc North America The North America ...</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>200</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2838</th>\n",
       "      <td>IONQ</td>\n",
       "      <td>ionq</td>\n",
       "      <td>IonQ Inc It 20 The Amazon Web Services AWS Ama...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>200</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5162</th>\n",
       "      <td>CIDM</td>\n",
       "      <td>cinedigm</td>\n",
       "      <td>Cinedigm Corp United States The Cinema Equipme...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>200</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>VMW</td>\n",
       "      <td>vmware</td>\n",
       "      <td>VMware Inc United States It VMware VMware VxRa...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>642</th>\n",
       "      <td>NTAP</td>\n",
       "      <td>netapp</td>\n",
       "      <td>NetApp Inc It Hybrid Cloud Public Could The Ne...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     ticker     title                                            summary  \\\n",
       "251    AMZN    amazon  Amazoncom Inc North America The North America ...   \n",
       "2838   IONQ      ionq  IonQ Inc It 20 The Amazon Web Services AWS Ama...   \n",
       "5162   CIDM  cinedigm  Cinedigm Corp United States The Cinema Equipme...   \n",
       "203     VMW    vmware  VMware Inc United States It VMware VMware VxRa...   \n",
       "642    NTAP    netapp  NetApp Inc It Hybrid Cloud Public Could The Ne...   \n",
       "\n",
       "      ratio_ticker  ratio_title  ratio_summary  ratio_total  \n",
       "251              0          100            200          300  \n",
       "2838             0            0            200          200  \n",
       "5162             0            0            200          200  \n",
       "203              0            0            100          100  \n",
       "642              0            0            100          100  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mymodel.predict(\"Amazon\", predict_type=\"test\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
